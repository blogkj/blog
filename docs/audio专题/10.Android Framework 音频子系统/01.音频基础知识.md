---
title: Android Framework 音频子系统（01）音频基础知识
date: 2022-06-09 17:01:09
permalink: /pages/6ec240/
categories:
  - audio专题
  - Android Framework 音频子系统
tags:
  - audio
  - Framework
  - Android
author: 
  name: zhouzichun
  link: https://github.com/blogkj
---
## 1 音频技术历史简介

留声机起源：在1877年秋天8月15日的下午，发明家爱迪生在自己的实验室，对着一个圆筒状的装置朗读了这样一句歌词：“玛丽抱着羊羔，羊羔的毛象雪一样白 ”。这一句只有8秒钟的话立即被这个装置回放出来，这就是爱迪生发明的留声机。这句歌词也成为了世界上第一段被录下来的声音。这台留声机由金属大圆桶、曲轴、受话机和膜板构成。录音的时候，先在圆桶上贴一张锡箔，然后将受话器细针端对准圆桶，匀速转动圆桶，对受话器的另一端说话，声音则被振动的细针记录在锡箔上。回放的时候，将细针端再拿回到圆桶的最开始处，转筒圆桶，声音就被原样播放出来。

钢丝录音和磁带的时代：爱迪生的留声机是纯机械录音技术，在这之后，录音技术发展为光学录音、磁性录音和电子录音。其中，光学录音顾名思义就是将声音信号转变为光学信号，记录在感光底片上的一种技术，最初应用在有声电影的研究上，并在最早的电影领域取得了广泛的应用，我们小时候看的露天电影大部分都还是用的这一类技术。在电影胶片的一侧有一条窄条，叫做声带，播放时由播放机转变为同步的声音信号予以伴音。需要说明的是，光学录音由于对制作技术环节要求较高，且不可擦写，所以当时除了电影伴音这部分应用广泛发展外，其他应用面较为狭窄。磁性录音是非常广泛的录音技术，最具代表性的革新就是1900年钢丝录音机的发明。钢丝录音机利用磁性录音原理，将受话器与电磁铁连接，将声音 信号首先转换为不断变化的磁信号，然后将钢丝与电磁铁紧密贴在一起并匀速转动，这样钢丝上就形成了强度随声音信号变化而变化的磁场，回放的时候只需要把钢丝重新在电磁铁上经过一次，声音就被还原出来，看到这里大家想必已经联想到我们熟知的磁带，没错，磁带录音机就是钢丝录音机的改进版本，只是现代人把钢丝改为了软质的塑料磁带而已。钢丝录音机以及以及磁性录音技术在录音发展史上占据着非常重要的地位，在后来人们发明将磁信号转变为电信号之前，全球几乎所有的声音都以这种方式保存和回放。最后说说电子录音。电子录音其实是脱胎于磁性录音的一种技术，是钢丝录音的电子化革新。电子录音的兴起源于人们对电信号放大技术的掌握，与磁性录音不同的是，电子录音将声音变化引起的磁信号的变化转换为微弱的电流变化，利用电子放大器将电流放大，从而得到记录声音的电信号。时至今日，这仍是我们主要的录音技术，比如我们使用的录音笔，MP3等都是电子录音技术。

唱片和唱片机：说完了录音，我们再来说说存储和播放。留声机发明之后，声音最开始的载体是上面说过圆桶上的那层锡箔纸。很快，科学家们将其改良为圆盘，这就是唱片的雏形。在数字音乐CD诞生之前，声音的载体都是以唱片的形式存在，至今仍有少数人痴迷于唱片。唱片和唱机的发展史基本上与录音技术发展史紧密联系，伴随着录音技术的发展。从最初的机械唱机到后来的磁性唱机，基本上有什么样的录音技术，就会有什么样的回放设备，因为录音和回放本就是一个互逆过程。

CD技术：CD技术距今只有30年的历史，是唱片发展到一定阶段后的进一步技术变革，与唱片技术的最大区别在于存储方式的不同。CD是一种纯数字的音乐存储方式，将声音信号先以编码的方式转换为0和1的数字信号，然后将这些数字信号存储到光盘中，而之前的唱片上保存的则是纯粹的模拟信号。由于在制作成本、易于保存等方面的天生优势，CD的出现迅速终结了唱片和相应唱机的统治，成为新一代音乐的载体广为流传。因为有了CD，模拟唱片和老式的唱机完成自己的历史使命， 退出历史舞台。CD的诞生也是人类数字科技进步的必然结果。近几十年里，CD对我们生活的影响可谓巨大，除了对音乐的存储，CD光盘很快也成为一种计算机数据存储载体，在计算机领域乃至整个科学研究领域都有非常广泛的应用。不但如此，经过技术的不断革新，CD所衍生的DVD和蓝光光盘正在成为娱乐我们生活的重要设备，成为我们生活和工作无法分割的一部分。

麦克风：它是录音环节中负责收集声音的设备，在最初的机械录音中，麦克风 （受话器）负责将声音信号转换为振膜的振动，并将这种振动传递给细针，以刻录锡箔。后来，磁性录音技术的崛起，麦克风也随之发展成为一种将声音信号转换为电信号的设备，从物理结构上大致分为动圈麦克风和电容麦克风。其中，动圈式麦克风由振膜、永磁铁和线圈组成，声音带动振膜振动，振膜推动线圈在磁铁的磁场中上下运动，产生的电流即为声音信号；电容式麦克风由两片极板组成，一片固定，一片与振膜合在一起。声音信号推动振膜振动，两片极板之间的距离产生变化，之间的电容值随之变化，最后再将此值转换为电信号，最后得到声音信号。麦克风的作用非常广泛，一切需要收录声音的场合中都缺不了它。除了专业的录音室，我们的生活里随处可见他的身影，各式的会议中，农村的广播里，可录式的随身听里，语音聊天室，UC唱歌等等。随着数码存储的兴起，各式便携设备中也都会整合这一功能，手机这一现代化最伟大的通讯工具中，也离不开麦克风的应用。当然麦克风最伟大的贡献还是在于：将乐队或歌者的声音最忠实的记录下来，让我们能随时随地的聆听，也让我们能永远的把它们保存下去。

扬声器：它是将一切声音信号转换为声音的终端装置，在整个发生链中处于最末端。扬声器的种类很多，除了我们最常见的电动扬声器外，还有气动扬声器（比如火车或者轮船的喇叭），静电扬声器等等。在最古老的机械式唱机中，扬声器甚至只是一个物理的扩音器而已。不过，我们最熟悉、应用范围最广的还是电动势扬声器。扬声器技术从诞生到今天所经历的变革并不大，基本原理都是将不断变化的电信号通过身处磁场的线圈，用线圈的动能推动振膜振动从而发声，现如今已经遍布在我们的工作和生活的周围环顾一下你的四周，你的笔记本电脑里面，你的电脑旁边，你的电视里面，你的车里。你的手机里……，到处都有扬声器， 有那个能主动发声的东西。因为有了它，我们收藏美丽声音的梦想得以实现。同时 耳机其实是一种近场聆听的扬声器，一般都紧贴耳朵甚至干脆塞进耳朵里去。从结构层面讲，耳机和扬声器原理基本一样，可以理解为扬声器的一种变种。

## 2 音频基础知识

原始的留声机有两个功能：记录声音和播放声音，它们都需要母盘来实现。记录声音是通过探针振动，在旋转的母盘面刻下条纹；播放声音是旋转唱片，母盘条纹带动探针动，带动振动膜发声振动。

### 2.1 声音如何量化

如何使用数字信号来记录声音？将电信号数字化存储（记录声音）。现实生活中，我们听到的声音都是时间连续的，我们把这种信号叫模拟信号。模拟信号(连续信号)通过一个受声音影响的电阻，将声音信号转换为电信号（电压高低），即量化成数字信号(离散的、不连续的信号)，之后在计算机中使用。量化的5个步骤如下：

模拟信号：现实生活中的声音表现为连续的、平滑的波形，其横坐标为时间轴，纵坐标表示声音的强弱。
采样：按照一定的时间间隔在连续的波上进行采样取值。
量化：将采样得到的值进行量化处理，也就是给纵坐标定一个刻度，记录下每个采样的纵坐标的值。
编码：将每个量化后的样本值转换成二进制编码。
数字信号：将所有样本二进制编码连起来存储在计算机上就形成了数字信号。
### 2.2 量化的基本概念

采样大小：采样精度，一个采样用多少个bit存放，常用的是16bit(这就意味着上述的量化过程中，纵坐标的取值范围是0-65535，声音是没有负值的)。
采样率：采样频率(1秒采样次数)，一般采样率有8kHz、16kHz、32kHz、44.1kHz、48kHz等，采样频率越高，声音的还原就越真实越自然，当然数据量就越大。模拟信号中，人类听觉范围是20-20000Hz，如果按照44.1kHz的频率进行采样，对20HZ音频进行采样，一个正玄波采样2200次；对20000HZ音频进行采样，平均一个正玄波采样2.2次。
声道/通道(channel)数：为了播放声音时能够还原真实的声场，在录制声音时在前后左右几个不同的方位同时获取声音，每个方位的声音就是一个声道。声道数是声音录制时的音源数量或回放时相应的扬声器数量，有单声道、双声道、多声道。声道多，效果好，两个声道，说明只有左右两边有声音传过来，四声道，说明前后左右都有声音传过来
码率：比特率，是指每秒传送的bit数。单位为 bps(Bit Per Second)，比特率越高，每秒传送数据就越多，音质就越好。
### 2.3 音频压缩方法简介（常见的2种方法）

消除冗余数据：这种压缩的主要方法是去除采集到的音频冗余信息，这些被删除掉的音频信号是没法恢复的，所以称为有损压缩。冗余信息包括人类听觉范围之外的音频信号和被掩蔽掉的音频信号。

哈夫曼无损编码：将人类无法识别的声音信号删除掉后，对剩余的声音信号继续进行压缩编码，经过这种压缩后再还原时是可以复原到和原来一样的数据的(当然，复原也只是复原到压缩前的状态，那些删除的人类无法识别的部分是不能复原的)，所以称为无损压缩。

### 2.4 音频编解码器

常见的音频编解码器包括 OPUS、AAC、Vorbis、Speex、iLBC、AMR、G.711等。目前泛娱乐化直播系统采用rtmp协议，支持AAC和Speex。性能上来看，OPUS > AAC > Vorbis，其它的正逐渐被淘汰。接下来对AAC的规格和格式进行说明。

AAC目前常用的规格有 AAC LC、AAC HE V1、AAC HE V2，如下：

AAC LC：(Low Complexity) 是低复杂度，一般码率128kbt/s。
AAC HE V1：是在AAC LC基础上加入了SBR(Spectral Band Replication)技术，也就是分频复用，加入这种技术后使码流变得更低，而且音质更好。比如按照44.1kHz采样率，20Hz频段一个正玄波采样2200个，这太浪费了，而在20000Hz频段一个正玄波采样2.2次，采样次数太少导致音质较差。采用SBR进行分频处理，在低频段降低采样率，在高频段提高采样率，这样既能降低码率又能提高音质。AAC HE V1一般码率为64kbt/s左右。
AAC HE V2：在AAC HE V1的基础上又增加了PS(Parametric Stereo)技术。也就是将立体声双声道分别保存，一个声道的数据完整保存，另一个声道只存储一些差异性的参数信息，因为两个声道信息相关性非常强，可以通过那些差异性参数来还原这个声道的信息。AAC HE V1一般码率为32kbt/s左右。
AAC的格式有ADIF和ADTS两种，如下：

AAC ADIF(Audio Data Interchange Format)：这种格式的AAC文件只在最开始的地方存有一个头，头里面包括采样率、采样大小、声道数等信息。每拿出一个音频帧都用这个头信息来进行解析。它只能从开头位置开始解码，一般用于磁盘文件中。
AAC ADTS(Audio Data Transport Stream)：这种格式的AAC文件在每一个音频帧的前面都有一个同步字，也就是加一个小的头(7-9个字节)，所以它可以从任何位置开始解码。它的优点就是进行流传输时每拿到一个音频帧直接就可以进行解码播放，缺点就是每个音频帧都多出一个头，所以相对于ADIF格式它会多出一些数据量。
2.5 部分音频格式说明

AAC：它是MPEG-2规范的一部分。AAC所采用的运算法则与MP3的运算法则有所不同，AAC 通过结合其他的功能来提高编码效率。AAC的音频算法在压缩能力上远远超过了以前的一些压缩算法（比如MP3等）。它还同时支持多达48个音轨、15个低频音轨、更多种采样率和比特率、多种语言的兼容能力、更高的解码效率。总之，AAC可以在比MP3文件缩小30%的前提下提供更好的音质。

APE：流行的数字音乐文件格式之一。与MP3这类有损压缩方式不同，APE是一种无损压缩音频技术，也就是说当你将从音频CD上读取的音频数据文件压缩成APE格式后，你还可以再将APE格式的文件还原，而还原后的音频文件与压缩前的一模一样，没有任何损失。

AIFF：是音频交换文件格式的英文缩写（Audio Interchange File Format）。是Apple公司开发的一种音频文件格式，被macintosh平台及其应用程序所支持，所以大家都不常见。AIFF是苹果电脑上面的标准音频格式，属于QuickTime技术的一部分。

AMR：全称Adaptive Multi-Rate，自适应多速率编码，主要用于移动设备的音频，压缩比比较大，但相对其他的压缩格式质量比较差，由于多用于人声，通话，效果还是很不错的。

CD：CD格式的音质是较高的音频格式。在大多数播放软件的“打开文件类型”中，都可以看到*.cda格式，这就是CD音轨了。标准CD格式也就是44.1K的采样频率，速率1411K/秒，16位量化位数。CD光盘可以在CD唱机中播放，也能用电脑里的各种播放软件来重放。

MIDI：全称（Musical Instrument Digital Interface），该格式被经常玩音乐的人使用，MIDI允许数字合成器和其他设备交换数据。MID文件格式由MIDI继承而来。MID文件并不是一段录制好的声音，而是记录声音的信息，然后再告诉声卡如何再现音乐的一组指令。这样一个MIDI文件每存1分钟的音乐只用大约5～10KB。MID文件主要用于原始乐器作品，流行歌曲的业余表演，游戏音轨以及电子贺卡等。*.mid文件重放的效果完全依赖声卡的档次。

MPEG：动态图象专家组的英文缩写，目网上音乐格式以MP3最为常见。虽然它是一种有损压缩，但是它的最大优势是以极小的声音失真换来了较高的压缩比。

MP3  MPEG音频文件的压缩是一种有损压缩，MPEG3音频编码具有10：1~12：1的高压缩率，同时基本保持低音频部分不失真，但是牺牲了声音文件中12KHz到16KHz高音频这部分的质量来换取文件的尺寸，相同长度的音乐文件，用 *.mp3 格式来储存，一般只有 *.wav 文件的1/10，因而音质要次于CD格式或WAV格式的声音文件。

MPEG-4  它采用了基于对象的压缩编码技术，在编码前首先对视频序列进行分析，从原始图像中分割出各个视频对象，然后再分别对每个视频对象的形状信息、运动信息、纹理信息单独编码，并通过比MPEG-2更优的运动预测和运动补偿来去除连续帧之间的时间冗余。其核心是基于内容的尺度可变性(Content-basedscalability)，可以对图像中各个对象分配优先级，对比较重要的对象用高的空间和时间分辨率表示，对不甚重要的对象(如监控系统的背景)以较低的分辨率表示，甚至不显示。因此它具有自适应调配资源能力，可以实现高质量低速率的图像通信和视频传输。占用资源少、灵活性强，网络性能好，适用范围更广。

OggVorbis：一种新的音频压缩格式，类似于MP3等现有的音乐格式。但有一点不同的是，它是完全免费、开放和没有专利限制的。Vorbis是这种音频压缩机制的名字，而Ogg则是一个计划的名字，该计划意图设计一个完全开放性的多媒体系统。该计划只实现了OggVorbis这一部分。OggVorbis文件的扩展名是*.OGG。这种文件的设计格式是非常先进的。这种文件格式可以不断地进行大小和音质的改良，而不影响旧有的编码器或播放器。VORBIS采用有损压缩，但通过使用更加先进的声音模型去减少损失，因此，同样位速率(BitRate)编码的OGG与MP3相比听起来更好一些。另外，还有一个原因，MP3格式是受专利保护的。如果你想使用MP3格式发布自己的作品，则需要付给Fraunhofer（发明MP3的公司）专利使用费。而VORBIS就完全没有这个问题。

RealAudio：主要适用于在网络上的在线音乐欣赏。real的的文件格式主要有这么几种：有RA（RealAudio）、RM（RealMedia，RealAudio G2）、RMX（RealAudio Secured），还有更多。这些格式的特点是可以随网络带宽的不同而改变声音的质量，在保证大多数人听到流畅声音的前提下，令带宽较富裕的听众获得较好的音质。

WAVE（*.WAV）是微软公司开发的一种声音文件格式，它符合PIFF “Resource Interchange File Format” 文件规范，用于保存Windows平台的音频信息资源，被Windows平台及其应用程序所支持。“*.WAV”格式支持MSADPCM、CCITT A LAW等多种压缩算法，支持多种音频位数、采样频率和声道，标准格式的WAV文件和CD格式一样，也是44.1K的采样频率，速率1411K/秒，16位量化位数，WAV格式的声音文件质量和CD相差无几，也是PC机上广为流行的声音文件格式，几乎所有的音频编辑软件都“认识”WAV格式。

## 3 音频系统底层设备节点简介
音频相关的设备节点在/dev/snd目录下，查看后 如下：  
![image.png](https://cdn.jsdelivr.net/gh/blogkj/tuchuang@master/audio/zhuangti/1654764866967-f0c007a8-db1b-45b8-b6e2-336c4736b735.png)  

接下来对这里面几个关键节点进行说明：
controlC0/controlC1：声卡0/声卡1，起控制作用。
pcmC0D0c/pcmC0D1c：recorder节点，用于录音。
pcmC0D0p/pcmC0D1p/pcmC1D0p：playback节点，用于播放。
说明：这里一个声卡可以有多个device，一个device有两个通道：录音和播放。
